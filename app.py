import streamlit as st
import torch
import clip
from PIL import Image
import numpy as np
from scipy.spatial.distance import cdist
import os
from pathlib import Path
import matplotlib.pyplot as plt

# ========== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==========
st.set_page_config(
    page_title="–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø–æ–∏—Å–∫",
    page_icon="üèõÔ∏è",
    layout="wide"
)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
DATASET_PATH = 'pexels_architecture_fixed'
EMBEDDINGS_FILE = 'clip_embeddings.npy'
PATHS_FILE = 'clip_image_paths.npy'
MODEL_NAME = 'ViT-B/32'
TOP_K = 5
IMAGE_SIZE = (224, 224)

# ========== –§–£–ù–ö–¶–ò–ò –î–õ–Ø –°–û–ó–î–ê–ù–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–• ==========

@st.cache_resource
def load_clip_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ CLIP"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load(MODEL_NAME, device=device)
    model.eval()
    return model, preprocess, device

def img_to_embedding(img_path, model, preprocess):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä"""
    try:
        img = Image.open(str(img_path)).convert('RGB')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω str()
        img_tensor = preprocess(img).unsqueeze(0)
        
        with torch.no_grad():
            embedding = model.encode_image(img_tensor)
            embedding /= embedding.norm(dim=-1, keepdim=True)
        
        return embedding.cpu().numpy().flatten()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {e}")
        return None

def create_database():
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    st.info("–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model, preprocess, device = load_clip_model()
    
    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    all_image_paths = []
    for ext in ('*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG'):
        all_image_paths.extend(Path(DATASET_PATH).rglob(ext))
    
    st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(all_image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    database_embeddings = []
    valid_paths = []
    progress_bar = st.progress(0)
    
    for i, img_path in enumerate(all_image_paths):
        emb = img_to_embedding(str(img_path), model, preprocess)
        if emb is not None:
            database_embeddings.append(emb)
            valid_paths.append(str(img_path))
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if (i + 1) % 50 == 0 or (i + 1) == len(all_image_paths):
            progress_bar.progress((i + 1) / len(all_image_paths))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã
    if database_embeddings:
        embeddings_array = np.vstack(database_embeddings)
        np.save(EMBEDDINGS_FILE, embeddings_array)
        np.save(PATHS_FILE, np.array(valid_paths))
        
        st.success(f"‚úÖ –ë–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞: {embeddings_array.shape[0]} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
        st.write(f"üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {embeddings_array.shape}")
        return embeddings_array, np.array(valid_paths)
    else:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
        return None, None

# ========== –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–ê ==========

@st.cache_data
def load_embeddings():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    if not os.path.exists(EMBEDDINGS_FILE):
        st.error(f"–§–∞–π–ª {EMBEDDINGS_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None, None
    
    embeddings = np.load(EMBEDDINGS_FILE)
    paths = np.load(PATHS_FILE, allow_pickle=True)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –ø—É—Ç–∏ –≤ —Å—Ç—Ä–æ–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
    paths_as_strings = [str(p) for p in paths]
    return embeddings, paths_as_strings

def get_image_embedding(image, model, preprocess, device):
    """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ñ–∞–π–ª –∏–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π)"""
    try:
        if hasattr(image, 'read'):  # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            img = Image.open(image).convert('RGB')
        else:  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            img = Image.open(str(image)).convert('RGB')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω str()
        
        img_input = preprocess(img).unsqueeze(0).to(device)
        with torch.no_grad():
            embedding = model.encode_image(img_input)
            embedding /= embedding.norm(dim=-1, keepdim=True)
        
        return embedding.cpu().numpy().flatten()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

def get_text_embedding(text, model, device):
    """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
    try:
        text_input = clip.tokenize([f"a photo of {text}"]).to(device)
        with torch.no_grad():
            embedding = model.encode_text(text_input)
            embedding /= embedding.norm(dim=-1, keepdim=True)
        
        return embedding.cpu().numpy().flatten()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return None

def search_by_image(query_image, model, preprocess, device, embeddings, paths, top_k=TOP_K):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    query_emb = get_image_embedding(query_image, model, preprocess, device)
    if query_emb is None:
        return []
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 2D –¥–ª—è cdist
    query_emb_2d = query_emb.reshape(1, -1)
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ
    similarities = 1 - cdist(query_emb_2d, embeddings, 'cosine')[0]
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
    return [(str(paths[idx]), similarities[idx]) for idx in top_indices]

def search_by_text(query_text, model, device, embeddings, paths, top_k=TOP_K):
    """–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É"""
    query_emb = get_text_embedding(query_text, model, device)
    if query_emb is None:
        return []
    
    # –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
    query_emb_2d = query_emb.reshape(1, -1)
    similarities = (embeddings @ query_emb_2d.T).flatten()
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
    return [(str(paths[idx]), similarities[idx]) for idx in top_indices]

def zero_shot_classify(query_image, model, preprocess, device, class_descriptions=None):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è"""
    if class_descriptions is None:
        class_descriptions = [
            "modern skyscraper with glass facade",
            "classical building with columns",
            "gothic cathedral with stained glass",
            "traditional wooden house",
            "brutalist concrete structure",
            "industrial warehouse with brick walls",
            "contemporary minimalist building",
            "art deco skyscraper",
            "medieval castle with towers",
            "modernist villa with clean lines"
        ]
    
    image_emb = get_image_embedding(query_image, model, preprocess, device)
    if image_emb is None:
        return []
    
    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    text_inputs = clip.tokenize(class_descriptions).to(device)
    
    with torch.no_grad():
        text_embeddings = model.encode_text(text_inputs)
        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ
        image_emb_2d = image_emb.reshape(1, -1)
        similarity = (100.0 * image_emb_2d @ text_embeddings.T)
        probs = similarity.softmax(dim=-1)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ø-5 –∫–ª–∞—Å—Å–æ–≤
        values, indices = probs[0].topk(min(5, len(class_descriptions)))
    
    return [(class_descriptions[idx], val.item()) for val, idx in zip(values, indices)]

# ========== –ì–õ–ê–í–ù–´–ô –ò–ù–¢–ï–†–§–ï–ô–° ==========

def main():
    st.title("üèõÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º CLIP")
    st.markdown("–°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model, preprocess, device = load_clip_model()
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        mode = st.radio(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
            ["üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É", "üñºÔ∏è –ü–æ–∏—Å–∫ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é", 
             "üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∏–ª—è", "üóÉÔ∏è –°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"]
        )
        
        top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:", 1, 20, TOP_K)
        
        st.divider()
        st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        if os.path.exists(EMBEDDINGS_FILE):
            embeddings_info = np.load(EMBEDDINGS_FILE)
            paths_info = np.load(PATHS_FILE, allow_pickle=True)
            st.write(f"**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:** {len(paths_info)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            st.write(f"**–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:** {embeddings_info.shape[1]}")
        else:
            st.warning("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
        
        st.write(f"**–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:** {device}")
        st.write(f"**–ú–æ–¥–µ–ª—å:** CLIP {MODEL_NAME}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    if mode == "üóÉÔ∏è –°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö":
        st.header("–°–æ–∑–¥–∞–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        st.warning("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!")
        
        if st.button("–°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö", type="primary"):
            if not os.path.exists(DATASET_PATH):
                st.error(f"–ü–∞–ø–∫–∞ {DATASET_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                return
            
            embeddings_new, paths_new = create_database()
            if embeddings_new is not None:
                st.success("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
                st.rerun()
    
    elif mode == "üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É":
        st.header("–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é")
        
        # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("modern glass skyscraper", width='stretch'):  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: use_container_width ‚Üí width='stretch'
                st.session_state.text_query = "modern glass skyscraper"
        with col2:
            if st.button("classical building with columns", width='stretch'):
                st.session_state.text_query = "classical building with columns"
        with col3:
            if st.button("gothic cathedral", width='stretch'):
                st.session_state.text_query = "gothic cathedral"
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        text_query = st.text_input(
            "–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:",
            value=getattr(st.session_state, 'text_query', 'modern building'),
            placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä: modern glass skyscraper"
        )
        
        if st.button("–ù–∞–π—Ç–∏", type="primary") or text_query:
            embeddings, paths = load_embeddings()
            if embeddings is None:
                st.error("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
                return
            
            with st.spinner("–ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
                results = search_by_text(text_query, model, device, embeddings, paths, top_k)
            
            if results:
                st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(results)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Å–µ—Ç–∫–µ
                cols = st.columns(min(4, len(results)))
                for idx, (col, (path, score)) in enumerate(zip(cols, results)):
                    with col:
                        try:
                            # path —É–∂–µ —Å—Ç—Ä–æ–∫–∞ –∏–∑-–∑–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ search_by_text
                            img = Image.open(path).convert('RGB')
                            st.image(img, width='stretch')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: use_container_width ‚Üí width='stretch'
                            st.caption(f"**–°—Ö–æ–¥—Å—Ç–≤–æ:** {score:.3f}")
                            st.caption(f"**–§–∞–π–ª:** {os.path.basename(path)}")
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            else:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    elif mode == "üñºÔ∏è –ü–æ–∏—Å–∫ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é":
        st.header("–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        uploaded_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞",
            type=['jpg', 'jpeg', 'png'],
            help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
        )
        
        # –ü—Ä–∏–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        st.write("–ò–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä –∏–∑ –±–∞–∑—ã:")
        embeddings, paths = load_embeddings()
        if embeddings is not None and len(paths) > 0:
            sample_cols = st.columns(4)
            sample_indices = np.random.choice(len(paths), 4, replace=False)
            for col, idx in zip(sample_cols, sample_indices):
                with col:
                    if st.button(f"–ü—Ä–∏–º–µ—Ä {idx+1}", key=f"sample_{idx}", width='stretch'):  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
                        st.session_state.sample_image = paths[idx]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        query_image = uploaded_file if uploaded_file else getattr(st.session_state, 'sample_image', None)
        
        if query_image:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
            col1, col2 = st.columns([1, 2])
            with col1:
                if hasattr(query_image, 'read'):
                    img = Image.open(query_image).convert('RGB')
                    st.image(img, caption="–í–∞—à –∑–∞–ø—Ä–æ—Å", width='stretch')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
                else:
                    st.image(query_image, caption="–í–∞—à –∑–∞–ø—Ä–æ—Å", width='stretch')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
            
            with col2:
                st.write("**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–ø—Ä–æ—Å–µ:**")
                if hasattr(query_image, 'name'):
                    st.write(f"**–ò–º—è —Ñ–∞–π–ª–∞:** {query_image.name}")
                    st.write(f"**–¢–∏–ø:** {query_image.type}")
                else:
                    st.write(f"**–ü—É—Ç—å:** {query_image}")
            
            if st.button("–ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ", type="primary") and embeddings is not None:
                with st.spinner("–ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
                    results = search_by_image(query_image, model, preprocess, device, embeddings, paths, top_k)
                
                if results:
                    st.subheader(f"üéØ –¢–æ–ø-{len(results)} –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
                    
                    # –°–µ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    for i in range(0, len(results), 4):
                        cols = st.columns(4)
                        for col_idx in range(4):
                            if i + col_idx < len(results):
                                path, score = results[i + col_idx]
                                with cols[col_idx]:
                                    try:
                                        # path —É–∂–µ —Å—Ç—Ä–æ–∫–∞ –∏–∑-–∑–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ search_by_image
                                        img = Image.open(path).convert('RGB')
                                        st.image(img, width='stretch')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
                                        
                                        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞
                                        st.progress(float(score))
                                        
                                        st.caption(f"**–°—Ö–æ–¥—Å—Ç–≤–æ:** {score:.3f}")
                                        st.caption(f"**{os.path.basename(path)}**")
                                    except Exception as e:
                                        st.error(f"–û—à–∏–±–∫–∞: {e}")
    
    elif mode == "üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∏–ª—è":
        st.header("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ç–∏–ª—è")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        uploaded_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            type=['jpg', 'jpeg', 'png']
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∞—Å—Å–æ–≤
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        
        default_classes = [
            "modern skyscraper with glass facade",
            "classical building with columns",
            "gothic cathedral with stained glass",
            "traditional wooden house",
            "brutalist concrete structure"
        ]
        
        custom_classes = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ (–∫–∞–∂–¥–æ–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏):",
            value="\n".join(default_classes),
            height=150,
            help="–ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å. –ù–∞–ø—Ä–∏–º–µ—Ä: 'modern glass building'"
        )
        
        class_list = [c.strip() for c in custom_classes.split('\n') if c.strip()]
        
        if uploaded_file and class_list:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            col1, col2 = st.columns([1, 2])
            with col1:
                img = Image.open(uploaded_file).convert('RGB')
                st.image(img, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", width='stretch')  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
            
            if st.button("–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å", type="primary"):
                with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å..."):
                    results = zero_shot_classify(uploaded_file, model, preprocess, device, class_list)
                
                if results:
                    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
                    
                    # –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
                    classes = [r[0] for r in results]
                    scores = [r[1] for r in results]
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    bars = ax.barh(classes, scores, color='skyblue')
                    ax.set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
                    ax.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Å—Ç–∏–ª–µ–π')
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫
                    for bar, score in zip(bars, scores):
                        width = bar.get_width()
                        ax.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                               f'{score:.2%}', va='center')
                    
                    st.pyplot(fig)
                    
                    # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                    st.subheader("üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
                    for i, (class_name, prob) in enumerate(results, 1):
                        st.write(f"{i}. **{class_name}** ‚Üí {prob:.2%}")
                        
                        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
                        st.progress(float(prob))

# ========== –ó–ê–ü–£–°–ö –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ==========
if __name__ == "__main__":
    main()