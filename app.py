import streamlit as st
import torch
import clip
from PIL import Image
import numpy as np
from scipy.spatial.distance import cdist
import os

# ========== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==========
st.set_page_config(page_title="–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø–æ–∏—Å–∫", layout="wide")

EMBEDDINGS_FILE = 'clip_embeddings.npy'  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ!
PATHS_FILE = 'clip_image_paths.npy'      # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ!
TOP_K = 5

# ========== –ó–ê–ì–†–£–ó–ö–ê ==========
@st.cache_resource
def load_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    model.eval()
    return model, preprocess, device

@st.cache_data
def load_embeddings():
    if not os.path.exists(EMBEDDINGS_FILE):
        st.error(f"–§–∞–π–ª {EMBEDDINGS_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None, None
    return np.load(EMBEDDINGS_FILE), np.load(PATHS_FILE, allow_pickle=True)

# ========== –ü–û–ò–°–ö ==========
def search_by_text(query, model, device, embeddings, paths, top_k=5):
    text_input = clip.tokenize([f"a photo of {query}"]).to(device)
    with torch.no_grad():
        text_emb = model.encode_text(text_input)
        text_emb /= text_emb.norm(dim=-1, keepdim=True)
    
    similarities = (embeddings @ text_emb.T).flatten()
    top_indices = np.argsort(similarities)[::-1][:top_k]
    return [(paths[i], similarities[i]) for i in top_indices]

def main():
    st.title("üèõÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø–æ–∏—Å–∫")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model, preprocess, device = load_model()
    
    # –†–µ–∂–∏–º—ã
    mode = st.sidebar.radio("–†–µ–∂–∏–º:", ["üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É", "üñºÔ∏è –ü–æ–∏—Å–∫ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é"])
    top_k = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:", 1, 10, 5)
    
    if mode == "üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É":
        query = st.text_input("–û–ø–∏—à–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:", "modern building")
        if st.button("–ù–∞–π—Ç–∏"):
            embeddings, paths = load_embeddings()
            if embeddings is None:
                st.error("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                st.info("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
                return
            
            results = search_by_text(query, model, device, embeddings, paths, top_k)
            cols = st.columns(top_k)
            for col, (path, score) in zip(cols, results):
                with col:
                    img = Image.open(path).convert('RGB')
                    st.image(img, use_container_width=True)
                    st.caption(f"–°—Ö–æ–¥—Å—Ç–≤–æ: {score:.3f}")
    else:
        st.write("–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–∑–∂–µ")

if __name__ == "__main__":
    main()
